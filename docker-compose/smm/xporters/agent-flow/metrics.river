// Config: Logging

logging {
  // https://grafana.com/docs/agent/latest/flow/reference/config-blocks/logging/
  level  = coalesce(env("GRAFANA_AGENT_LOG_LEVEL"), "info")
  format = "logfmt"
}

// Config: Tracing

tracing {
  // https://grafana.com/docs/agent/latest/flow/reference/config-blocks/tracing/
  sampling_fraction = 1
  write_to = [otelcol.processor.attributes.default.input]
}

// Discover Docker Containers

discovery.docker "docker_containers" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/discovery.docker/
  host = "unix:///var/run/docker.sock"
  refresh_interval = "30s"
}

discovery.relabel "docker_containers" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/discovery.relabel/
  targets = discovery.docker.docker_containers.targets
  rule {
    action        = "replace"
    source_labels = ["__address__"]
    target_label  = "container_address"
    regex         = "([^:]+)(:[0-9]+)?"
    replacement   = "${1}"
  }
  rule {
    action        = "replace"
    source_labels = ["__meta_docker_container_id"]
    target_label  = "container_id"
  }
  rule {
    action        = "replace"
    source_labels = ["__meta_docker_container_name"]
    target_label  = "pod"
    regex         = "/(.*)"
  }
  rule {
    action        = "replace"
    source_labels = ["pod"]
    target_label  = "app"
    regex         = "(.+?)(-\\d+)?"
    replacement   = "${1}"
  }
  rule {
    source_labels = ["app"]
    target_label  = "container"
  }
  rule {
    action        = "replace"
    source_labels = ["pod","__meta_docker_port_private"]
    target_label  = "instance"
    separator     = ":"
  }
  rule {
    action        = "replace"
    source_labels = ["__meta_docker_container_label_com_docker_compose_service"]
    target_label  = "job"
  }
  rule {
    action        = "replace"
    source_labels = ["__meta_docker_container_label_namespace"]
    target_label  = "namespace"
  }
  rule {
    action        = "replace"
    source_labels = ["__meta_docker_container_label_com_docker_compose_service"]
    target_label  = "service"
  }
}

// Metrics
// Docs (Scrape): https://grafana.com/docs/agent/latest/flow/reference/components/prometheus.scrape/
// Docs (Relabel): https://grafana.com/docs/agent/latest/flow/reference/components/prometheus.relabel/
// Docs (Remote Write): https://grafana.com/docs/agent/latest/flow/reference/components/prometheus.remote_write/

prometheus.exporter.agent "host" {
  // https://grafana.com/docs/agent/next/flow/reference/components/prometheus.exporter.agent/
}

prometheus.exporter.unix "host" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/prometheus.exporter.unix/
  include_exporter_metrics = true
  rootfs_path = "/rootfs"
}

prometheus.scrape "agent_exporter" {
  // Configure a prometheus.scrape component to collect agent_exporter metrics.
  targets    = prometheus.exporter.agent.host.targets
  forward_to = [prometheus.remote_write.mimir.receiver]
  scrape_interval = "14s"
   // Why does this need to be larger than the interval?  
}

prometheus.scrape "docker_containers" {
  targets = concat(
    discovery.relabel.docker_containers.output,
  )
  forward_to = [prometheus.relabel.docker_containers.receiver]
  scrape_interval = "14s"
   // Why does this need to be larger than the interval?
}

prometheus.scrape "docker_local" {
  targets = [
    {"__address__" = "docker.for.mac.host.internal:9323", "env" = "host"},
    {"__address__" = "host.docker.internal:9323", "env" = "host"},
  ]
  job_name = "monitoring/docker"
  forward_to = [prometheus.remote_write.mimir.receiver]
  scrape_interval = "14s"
   // Why does this need to be larger than the interval?
}

prometheus.scrape "minio" {
  targets = [
    {"__address__" = "minio:9000", "app" = "minio", "container" = "minio", "namespace" = "storage", "pod" = "minio", "service" = "minio", "version" = "v1"},
  ]
  job_name = "integrations/minio"
  metrics_path = "/minio/prometheus/metrics"
  forward_to = [prometheus.remote_write.mimir.receiver]
  scrape_interval = "14s"
   // Why does this need to be larger than the interval?
}

prometheus.scrape "minio_v2" {
  targets = [
    {"__address__" = "minio:9000", "app" = "minio", "container" = "minio", "namespace" = "storage", "pod" = "minio", "service" = "minio", "version" = "v2"},
  ]
  job_name = "integrations/minio"
  metrics_path = "/minio/v2/metrics/cluster"
  forward_to = [prometheus.remote_write.mimir.receiver]
  scrape_interval = "14s"
   // Why does this need to be larger than the interval?
}

prometheus.scrape "node_exporter" {
  // Configure a prometheus.scrape component to collect node_exporter metrics.
  targets    = prometheus.exporter.unix.host.targets
  forward_to = [prometheus.relabel.node_exporter.receiver]
  scrape_interval = "14s"
   // Why does this need to be larger than the interval?
}

prometheus.scrape "prometheus" {
  targets = [
    {"__address__" = "prometheus:9090", "app" = "prometheus", "container" = "prometheus", "pod" = "prometheus", "service" = "prometheus"},
  ]
  job_name = "prometheus"
  forward_to = [prometheus.remote_write.mimir.receiver]
  scrape_interval = "14s"
   // Why does this need to be larger than the interval?
}

prometheus.relabel "docker_containers" {
  forward_to = [prometheus.remote_write.mimir.receiver]
  rule {
    // Drop Services that dont expose Metrics (based on App Label)
    action        = "drop"
    regex         = "grafanadb|smtp-server"
    source_labels = ["app"]
  }
  rule {
    // Drop Services that dont expose Metrics (based on Service Label)
    action        = "drop"
    regex         = "agent.*|chronograf|kapacitor|mailpit|mariadb|.*minio.*|mysql|mythical-database|.*nginx.*|postgres|provisioning-python|redis|saml-idp|smtp-server"
    source_labels = ["service"]
  }
  rule {
    // Add "group" Label to Core Infrastructure Services
    source_labels = ["container"]
    regex         = "grafana|loki|mimir|phlare|prometheus|pyroscope|tempo"
    replacement   = "infrastructure"
    target_label  = "group"
  }
  rule {
    // Add "group" Label to Mythical Beasts Services
    source_labels = ["service"]
    regex         = "mythical.*"
    replacement   = "mythical"
    target_label  = "group"
  }
}

prometheus.relabel "node_exporter" {
  forward_to = [prometheus.remote_write.mimir.receiver]
  rule {
    action        = "replace"
    replacement   = "host"
    target_label  = "instance"
  }
  rule {
    action        = "replace"
    replacement   = "integrations/node_exporter"
    target_label  = "job"
  }
}


prometheus.remote_write "mimir" {
  endpoint {
    url = "http://gateway:8080/api/v1/push"
  }
  external_labels = {
    "cluster" = "docker-compose",
    "source"  = "agent-flow",
  }
}

// Logs

loki.relabel "docker_containers" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/loki.relabel/
  forward_to = [loki.process.docker_containers.receiver]
  rule {
    source_labels = ["__meta_docker_container_log_stream"]
    target_label  = "stream"
  }
  rule {
    action = "labeldrop"
    regex  = "instance"
  }
}

loki.process "docker_containers" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/loki.process/
  forward_to = [loki.write.local.receiver]
  stage.match {
    selector = "{app=\"grafana\"} |= \"logger=frontend\""
    stage.logfmt {
      mapping = { "app" = "", "kind" = "" }
    }
    stage.labels {
      values = {
        app_id = "app",
        kind = "",
      }
    }
    stage.static_labels {
      values = {
        source = "faro",
      }
    }
  }
  stage.regex {
    expression = "(level=(?P<log_level>[\\s]*debug|warn|info|error|warning|trace|exception|emerg|fatal|alert|crit|critical|err|eror|information|notice|dbug))"
  }
  stage.labels {
    values = {
      level = "log_level",
    }
  }
}

loki.source.docker "docker_containers" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/loki.source.docker/
  host          = "unix:///var/run/docker.sock"
  targets       = concat(
    discovery.relabel.docker_containers.output,
  )
  forward_to    = [loki.process.docker_containers.receiver]
  relabel_rules = loki.relabel.docker_containers.rules
}

local.file_match "varlogs" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/local.file_match/
  path_targets = [
    {"__path__" = "/var/log/local/{syslog,messages,*log}", "instance" = "host", "job" = "integrations/node_exporter"},
  ]
}

loki.source.file "varlogs" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/loki.source.file/
  targets    = local.file_match.varlogs.targets
  forward_to = [loki.write.local.receiver]
}

loki.write "local" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/loki.write/
  endpoint {
    url = "http://gateway:3100/loki/api/v1/push"
  }
  external_labels = {
    "cluster" = "docker-compose",
    "source"  = "agent-flow",
    "namespace" = "monitoring-system",
  }
}

// Profiling
// Docs (Scrape): https://grafana.com/docs/agent/latest/flow/reference/components/pyroscope.scrape/
// Docs (Remote Write): https://grafana.com/docs/agent/latest/flow/reference/components/pyroscope.write/

pyroscope.scrape "default" {
  targets = concat(
    discovery.relabel.docker_containers.output,
  )
  forward_to      = [pyroscope.write.local.receiver]
  scrape_interval = "14s"
   // Why does this need to be larger than the interval?
}

pyroscope.write "local" {
  endpoint {
    url = "http://pyroscope:4040"
  }
  external_labels = {
    "cluster" = "docker-compose",
    "env"     = "lab",
    "source"  = "agent-flow",
  }
}

// Traces

otelcol.receiver.otlp "default" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.receiver.otlp/
  http {}
  output {
    metrics = [otelcol.processor.attributes.default.input]
    logs    = [otelcol.processor.attributes.default.input]
    traces  = [otelcol.processor.attributes.default.input]
  }
}

otelcol.processor.attributes "default" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.processor.attributes/
  action {
    // Insert a "cluster" Attribute, only if it does not exist, and set value to "docker-compose".
    key = "cluster"
    value = "docker-compose"
    action = "insert"
  }
  action {
    // Insert a "source" Attribute, only if it does not exist, and set value to "agent-flow".
    key = "source"
    value = "agent-flow"
    action = "insert"
  }
  action {
    // Insert or Update an "env" Attribute and set value to "lab".
    key = "env"
    value = "lab"
    action = "upsert"
  }
  output {
    metrics = [otelcol.processor.batch.default.input]
    logs    = [otelcol.processor.batch.default.input]
    traces  = [otelcol.processor.batch.default.input]
  }
}

otelcol.processor.batch "default" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.processor.batch/
  output {
    metrics = [otelcol.exporter.prometheus.default.input]
    logs    = [otelcol.exporter.loki.default.input]
    traces  = [otelcol.exporter.otlp.default.input]
  }
}

otelcol.exporter.loki "default" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.exporter.loki/
  forward_to = [loki.write.local.receiver]
}

otelcol.exporter.prometheus "default" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.exporter.prometheus/
  include_scope_info   = true
  include_scope_labels = true
  include_target_info  = true
  forward_to           = [prometheus.remote_write.mimir.receiver]
}

otelcol.exporter.otlp "default" {
  // https://grafana.com/docs/agent/latest/flow/reference/components/otelcol.exporter.otlp/
  client {
    endpoint = "gateway:4317"
    tls {
      insecure = true
      insecure_skip_verify = true
    } // Send traces to a locally running Tempo without TLS enabled.
  }
}